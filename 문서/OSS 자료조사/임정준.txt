구글 텐서플로우

텐서플로우(TensorFlow)는 graph로 연산(computation)을 나타내는 프로그래밍 시스템 
입니다.
텐서플로우(TensorFlow)는 데이터플로우 그래프(Data flow graph)를 사용하여 
수치 연산을 하는 소프트웨어로 , 그래프의 노드(Node)는 수치연산을 나타내고 
엣지(edge)는 노드사이를 이동하는 다차원 데이터 배열(tensor)를 나타내 줍니다.



특징
● 데이터 플로우 그래프를 통한 풍부한 표현력
● 코드 수정 없이 CPU/GPU모드로 동작
● 아이디어 테스트에서 서비스 단계까지 이용가능 
● (distributed)실행환경이 가능함
● 계산 구조와 목표 함수만 정의하면 자동으로 미분 계산을 처리
● Python/C++를 지원하며, SWIG를 통해 다양한 언어 지원 가능 

 
관련소프트웨어

● 텐서보드(TensorBoard)
기본적으로 텐서플로우에 내장된 그래프 시각화 소프트웨어
텐서플로우 실행 중의 log파일을 이용해 모델의 동작을 살핌
통계요약, 학습 분석, 디버깅 등에 도움을 줌 

● 텐서플로우 서빙 (Tensor Serving)
학습된 텐서플로우 모델을 쉽게 활용할 수 있는 소프트웨어로 내장된 함수를 사용하여
 자신의 모델을 export하고 이를 텐서플로우 서빙에서 사용 함

https://m.blog.naver.com/kimkanu/221116429423





SVM (Support Vector Machine) 은 분류 , 회귀 및 특이 치 탐지에 사용되는 일련의 
감독 학습 방법
서포트 벡터 머신(support vector machine)은 기계 학습의 분야 중 하나로 패턴 인식, 자료 분석을 위한 지도 학습 모델이며, 주로 분류와 회귀 분석을 위해 사용한다.
 두 카테고리 중 어느 하나에 속한 데이터의 집합이 주어졌을 때, SVM 알고리즘은 주어진 데이터 집합을 바탕으로 하여 새로운 데이터가 어느 카테고리에 속할지 판단하는 
비확률적 이진 선형 분류 모델을 만든다. 만들어진 분류 모델은 데이터가 사상된 공간에서 경계로 표현되는데 SVM 알고리즘은 그 중 가장 큰 폭을 가진 경계를 찾는 알고리즘이다.
 SVM은 선형 분류와 더불어 비선형 분류에서도 사용될 수 있다. 비선형 분류를 하기 위해서 주어진 데이터를 고차원 특징 공간으로 사상하는 작업이 필요한데, 
이를 효율적으로 하기 위해 커널 트릭을 사용하기도 한다.

서포트 벡터 머신의 장점

● 고차원 공간에서 효과적입니다.
● 치수 수가 샘플 수보다 큰 경우에도 여전히 효과적입니다.
● 의사 결정 기능 (지원 벡터라고 함)에 훈련 지점의 하위 집합을 사용하므로 메모리 효율성도 높습니다.
● 다용도 : 의사 결정 기능에 대해 다른 커널 기능을 지정할 수 있습니다. 일반적인 커널이 제공되지만 사용자 정의 커널을 지정할 수도 있습니다.

서포트 벡터 머신의 단점

● 피처 수가 샘플 수보다 훨씬 많은 경우 커널 기능 을 선택할 때 과적 합을 피하고 정규화 용어가 중요합니다.
● SVM은 확률 추정치를 직접 제공하지 않으며 값 비싼 5 배 교차 검증을 사용하여 계산됩니다.


사이 킷 -------------- https://scikit-learn.org/stable/index.html
파이썬
● 데이터 마이닝 및 데이터 분석을위한 간단하고 효율적인 도구
● 모든 사람이 접근 할 수 있으며 다양한 상황에서 재사용 가능
● NumPy, SciPy 및 matplotlib 기반
● 상업적으로 사용 가능한 오픈 소스-BSD 라이센스 


파이썬으로 구현된 데이터 분석 라이브러리다.
잘 정의된 알고리즘과 검증된 라이브러리라는 점이 장점이다.
아나콘다를 설치했다면 기본으로 설치되있다.

Scikit-learn에서는 머신러닝 실습을 위해 데이터를 활용할 수 있는 API를 제공한다.
데이터셋은 일반적으로 매우 유명한 데이터셋(iris, boston_price 등)이며, 대부분 전처리가 되어있어서 
결측치 처리등의 전처리가 필요없다.
또한, 데이터셋이 작은 toy dataset과 사이즈가 큰 real world dataset이 존재한다.


데이터의 구조가 거의 동일하며, 데이터를 load하면 dictionaey-like-object로 구성돼있다.
독립변수는 key data로, 종속변수는 key target으로 추출가능하다.

일반적으로 scikit-learn을 이용하여 실습할 때 아래와 같은 절차로 진행된다.


1. 데이터 입력 : 데이터 load(scikit-learn datasets class활용).    X, Y구분
2. 전처리 : 결측치 및 이상치 처리, 추가 변수 생성, 변수 선택 등
3. 데이터셋 분리 : 학습용 데이터와 모델 검증용 데이터로 구분, Scikit-learn model_selection의 train_test_split 함수 활용
4. 데이터 모델링 : 모델의 객체를 생성(ex. mlr = LinearRegression()), 
                  모델 학습(fit 함수 활용)
5. 파라미터 튜닝 : Grid & Random Search와 Cross-validation을 통한 최적 파라미터 
                  탐색, 머신러닝 모델링에서 핵심적인 부분이며 뒷 포스팅에서 다루겠다.
6. 모델 결과 확인 : 모델 예측치 계산(predict함수 활용), Scikit-learn 내의 metrics 
                   모듈에서 각종 평가지표 활용(RMSE, accuracy 등)


KNeighbors의 기본 원리는 새로운 점에 가장 가까운 사전 정의 된 수의 훈련 샘플을 찾아 
이들로부터 라벨을 예측하는 것입니다. 샘플의 수는 사용자 정의 상수 
(k- 최근 접 이웃 학습) 일 수 있거나 
점의 로컬 밀도 (반경 기반 이웃 학습)에 따라 달라집니다. 일반적으로 거리는 모든 측정 기준일 수 있습니다. 
표준 유클리드 거리가 가장 일반적인 선택입니다. 이웃 기반 방법은 모든 일반 학습 데이터를 
단순히 "기억"하기 때문에 (일반적으로 볼 트리 또는 KD 트리 와 같은 빠른 색인 구조로 변환되기 때문에) 일반화되지 않은 기계 학습 방법으로 알려져 있습니다.

단순함에도 불구하고 가장 가까운 이웃은 자필 숫자 및 위성 이미지 장면을 포함하여 많은 
분류 및 회귀 문제에서 성공했습니다. 
비모수 적 방법이기 때문에 결정 경계가 매우 불규칙한 분류 상황에서 종종 성공합니다.

 클래스는 sklearn.neighborsNumPy 배열 또는 scipy.sparse행렬을 입력으로 처리 할 수 있습니다 . 
밀도가 높은 매트릭스의 경우 가능한 많은 거리 메트릭이 지원됩니다. 희소 행렬의 경우 검색을 위해 임의의 Minkowski 메트릭이 지원됩니다.

Pinpoint 서비스는 분산 서비스 및 시스템의 성능 분석/진단/추적 플랫폼 서비스로서 “N” 계층의 SOA(Service Oriented Architecture) 및 
Micro-Service로 구성된 아키텍처 서비스의 추적 및 분석 기능을 제공하고, 분산 애플리케이션의 트랜잭션 분석, Topology Detection, Bytecode Instrumentation을 활용한 
진단 기능을 제공합니다.

-네이버 개발자센터



